{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols =np.mean(X,axis=0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols =np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm =(X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06581410364e-18\n",
      "-1.74678103504\n",
      "1.72928849189\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis=0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis=0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 1, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices =np.random.permutation(X_norm.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[733 623 626 451 850 938  67 752  22 268 299 255 649  43 670 814 312 320\n",
      " 599 494 191 149 316 851 688  76 285 123 967 238 817 810  48  19 493 853\n",
      " 228 266 864 936   8 715 825 740 664 684 924 837 552 217 554 372 707  50\n",
      " 424 249 496 809 308 236 134  18 448 207 769  30 597  12 636 939 311 773\n",
      " 760 624 988 600 901 962  34 335 566 742 950 993 279 396 388  40 161 667\n",
      " 547 926 925 258 813 310 706 601 770 957 831  17 158 160 165 518 409 345\n",
      " 369 961 491 315 271 806 994 694 108 453 960 484 437 955 442 550 798 528\n",
      "  33  60 987 757 782 241 696 561 582 970 644 481 663 545 710 859 612 118\n",
      " 822 869 179 711 787 933 403 856 648 965 468 797 556 701 772 119 792 807\n",
      " 553 139 511 381 833   5 220 317 652 565 533 246 140 328  24 610 690 885\n",
      " 307 786 414 148 680  87 705 169 861 305 284 275 591 273 929 184 849 505\n",
      " 480 979 656 443 187 951 999 695 189 847   9 438 146 588 836 264 261 446\n",
      " 803 495 729 889  83 447 909 513 799 195 629 286 789 272 302 551 215 180\n",
      " 509 977  39 980 479 474 683 141   6 351 982 700 743 642 633 943 963 522\n",
      " 658 890 444 188 367 686 499 679 834 546 763  21 589 508 800 332 278 754\n",
      " 538 791 172 774 405 343 128 364 393 375 429 267 318 832 638 713 101 300\n",
      " 557 175  13 282 205 462 914  97 764 391 235 247 342 829 290 870 415 574\n",
      " 370  72 344  42  78 768 445 346 744 482 520 746 661 265 486 237  84 675\n",
      " 441 154 983 427 472 985 756 461 177 795  66  35 843 361 934 753 580 703\n",
      " 902 576 907  45 704 430 174  51  80 873 422 724 842 674 325 654 905 989\n",
      " 567 378  29 784 281 492 596 340 976 104  92 891 954 168 339 659 911 466\n",
      " 750 815 230 673  74 794 291 866 990  14 242 886  77  25  73 469 485 353\n",
      " 898 604 824 527 912 333 741 609 972 526 716 998 548 502 816 586 555 324\n",
      " 199 579 488 719 532 152 306  55 964 164 321 355 767 412 892 274 240 868\n",
      " 863 530 751 293 738 171 257  59 945 471 304 593  94  36 109 790 681 383\n",
      " 618 368 454 386 635 839  57 136   7 389 232 801 103 500 762 208 352 366\n",
      " 223  98 450 804  86 395 919 193 631 382 408 858 540 637 127 737 620 709\n",
      " 852 303 137 788  52 309 581  41 224 918 735 598 877 867 841 621 865 630\n",
      " 818 920 399 487 357 854 331 289 932 478 507 944 611 731 560 968 783 916\n",
      "   2 221 563 449 922 459 894 906  75 883 338 280 908 153 122 515 874 645\n",
      " 946  46 147 319 330 523  20 131 897 974 720 973 682 718   3  88 811 252\n",
      " 222 326 129 689 986 544 440 287 619 113 204 595 827 213 820 662 766  71\n",
      "  99 650 426 519 627 966 173 420 501 225 812 730 143 915 421 899 185 699\n",
      "  49 691 377 470 243 900 121 476 614 722 126  32 359 102 473 245 602 996\n",
      " 714 857  65 114 931 433 846 155 978 732 568 231 400 558 467 107 254 584\n",
      " 431 708 263 117 410 201 183 314 397 848 115 678 653 727 721 921 297 884\n",
      " 539 329 728 111 808 504 802 239 373  64 606 120 779 525 562 775 639 194\n",
      " 313 200 622 793 514 617 510 651 435 702  10 394 592 640 780 219 872  63\n",
      " 995 572 125 577 860 112 419 759 564 747  31 475 958 248 634 693  47 616\n",
      " 632 776 712 416 971 138 745 436 917 170 845 573 181 296 761 823 365 457\n",
      " 671 643 669 913 992 387 178  44 940 301  70 893 826  79 879 262 384 665\n",
      " 717 206 202 227 534 477 559 251 336 132 677 322 341 463 371  91  27 233\n",
      "  58 536 687 953  89 840 458 298 590 835 229 133 569 186 323 904 196 214\n",
      " 404 226 529 723 182 531 615 896 337 956 660 625 578 571 150 878 292 796\n",
      " 506 401 411  68 941 542  56 418 348 830 456 130 641 392  11 575 464 778\n",
      "  81 855 698 406 455 949 927 981 676 543  61 497 781 398 116 685 439 947\n",
      " 162 666 828 376 413 244 952 739 819 570 417 613 948 930   1  37 218 959\n",
      " 157  16 260 777  95  69 517 628  15  54 725 887 167   0 594 541 785 347\n",
      "  93 524 209 176 697 937  62 871 805 821 489 203 234 362 512 583 190 163\n",
      " 434 765 935 888 374 380 876 608 692 151 402 657 726 100 452  90   4 159\n",
      " 423  23 197 549 294 145 838 277 363 881 425 358 385 875 428 537 211 672\n",
      " 407 379 142 253 270 587 521 655 349  26 942 895 327  28 156 460 110 585\n",
      " 668 216 862 755 198 334 354 432 607 210 605 356 910 975 997 646 105 259\n",
      " 483 503 882  85  53 212 535 256 923 350 295 360 736 991 144 192 516 276\n",
      " 647 771 734 283  82 603 166 903 844 928 288 748 269 465 984 490 758 250\n",
      " 135 390 106 969  96  38 498 749 880 124]\n"
     ]
    }
   ],
   "source": [
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 200 200\n"
     ]
    }
   ],
   "source": [
    "n_train=int(0.6*X_norm.shape[0])\n",
    "n_crossVal=int(0.2*X_norm.shape[0])\n",
    "n_test=int(0.2*X_norm.shape[0])\n",
    "\n",
    "print(n_train, n_crossVal, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "n_train=int(0.6*X_norm.shape[0])\n",
    "n_crossVal=int(0.2*X_norm.shape[0])\n",
    "n_test=int(0.2*X_norm.shape[0])\n",
    "\n",
    "# Create a Training Set\n",
    "X_train =X_norm[:n_train]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal =X_norm[n_train:n_train+n_test]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test =X_norm[n_train+n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
